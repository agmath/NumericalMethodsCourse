{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSgwFdg8PZgaRBr0YzPnsF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ts0LQ2-z3emd","executionInfo":{"status":"ok","timestamp":1684933602272,"user_tz":240,"elapsed":3,"user":{"displayName":"Adam Gilbert","userId":"02074648007699947871"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["# Day 25: Runge-Kutta Methods\n","\n","In the previous notebook we considered Euler's Method as a method for constructing an approximate solution to the IVP $\\vec{y}' = \\vec{F}\\left(x, \\vec{y}\\right)$ where $\\vec{y}\\left(a\\right) = \\vec{\\alpha}$. Euler's Method used the Taylor Series truncated after the linear term (essentially a tangent line/plane/hyperplane) to construct the approximate solution using piecewise linear components over steps of size $h$. We could construct more precise approximate solutions by keeping additional terms of the Taylor Series before truncating. For example, an $n^{th}$-order method could use the truncated Taylor Series\n","\n","$$\\vec{y}\\left(x + h\\right) = \\vec{y}\\left(x\\right) + \\vec{y}'\\left(x\\right)h + \\frac{1}{2!}\\vec{y}''\\left(x\\right)h^2 + \\cdots + \\frac{1}{n!}\\vec{y}^{\\left(n\\right)}\\left(x\\right)h^n$$\n","\n","The problem with this is that we need to compute, store, and utilize $n$ derivatives of $\\vec{y}$ by repeated differentiation of $\\vec{y}' = \\vec{F}\\left(x, \\vec{y}\\right)$.\n","\n","*Runge-Kutta* methods avoid the need to compute these derivatives."],"metadata":{"id":"pa--75C93lvi"}},{"cell_type":"markdown","source":["## Second-Order Runge-Kutta Method\n","\n","A second-order *Runge-Kutta* method assumes an approximate solution of the form\n","\n","$$\\vec{y}\\left(x + h\\right) = \\vec{y}\\left(x\\right) + c_0\\vec{F}\\left(x, \\vec{y}\\right)h + c_1\\vec{F}\\left(x + ph, \\vec{y} + qh\\vec{F}\\left(x, \\vec{y}\\right)\\right)$$\n","\n","Where $c_0$, $c_1$, $p$, and $q$ are found by matching the terms of the equation above to the terms of the Taylor Series\n","\n","\\begin{align*}\\vec{y}\\left(x + h\\right) &= \\vec{y}\\left(x\\right) + \\vec{y}'\\left(x\\right)h + \\frac{1}{2!}\\vec{y}''\\left(x\\right)h^2\\\\\n","&= \\vec{y}\\left(x\\right) + \\vec{F}\\left(x, \\vec{y}\\right)h + \\frac{1}{2!}\\vec{F}'\\left(x, \\vec{y}\\right)h^2\\\\\n","&= \\vec{y}\\left(x\\right) + h\\left(\\vec{F}\\left(x, \\vec{y}\\right) + \\frac{h}{2}\\vec{F}'\\left(x, \\vec{y}\\right)\\right)~~~~~(\\bigstar)\n","\\end{align*}\n","\n","We'd really like to replace $\\vec{F}\\left(x, \\vec{y}\\right) + \\frac{h}{2}\\vec{F}'\\left(x, \\vec{y}\\right)$ with something simpler -- something of the form $s\\vec{F}\\left(x + r, \\vec{y} + t\\vec{F}\\left(x, \\vec{y}\\right)\\right)$ so that we can avoid computing $\\vec{F}'\\left(x, \\vec{y}\\right)$.  Recalling that $\\frac{d}{dx}\\left[\\vec{F}\\left(x, \\vec{y}\\right)\\right]$ is the sum of the partial derivatives, we have\n","\n","\\begin{align*} \\vec{F}'\\left(x, \\vec{y}\\right) &= \\frac{\\partial}{\\partial x}\\left[\\vec{F}\\left(x, \\vec{y}\\right)\\right] + \\sum_{i=0}^{n-1}{\\frac{\\partial}{\\partial y_i}\\left[\\vec{y}'\\right]}\\\\\n","&= \\frac{\\partial \\vec{F}}{\\partial x} + \\sum_{i=0}^{n-1}{\\frac{\\partial}{\\partial y_i}\\left[\\vec{F}\\left(x, \\vec{y}\\right)\\right]}\\\\\n","&= \\frac{\\partial \\vec{F}}{\\partial x} + \\sum_{i=0}^{n-1}{\\frac{\\partial \\vec{F}}{\\partial y_i}F_i\\left(x, \\vec{y}\\right)}\n","\\end{align*}\n","\n","Since this is the case, we can substitute our expression for $\\vec{F}'\\left(x, \\vec{y}\\right)$ into the simplified Taylor Series truncated to degree two (line $\\bigstar$ above), to obtain\n","\n","\\begin{align*} \\vec{y}\\left(x + h\\right) &\\approx \\vec{y}\\left(x\\right) + h\\left(\\vec{F}\\left(x, \\vec{y}\\right) + \\frac{1}{2!}\\vec{F}'\\left(x, \\vec{y}\\right)h\\right)\\\\\n","&= \\vec{y}\\left(x\\right) + h\\left(\\vec{F}\\left(x, \\vec{y}\\right) + \\frac{h}{2}\\left[\\frac{\\partial \\vec{F}}{\\partial x} + \\sum_{i=0}^{n-1}{\\frac{\\partial \\vec{F}}{\\partial y_i}F_i\\left(x, \\vec{y}\\right)}\\right]\\right)\\\\\n","&= \\vec{y}\\left(x\\right) + h\\left(\\vec{F}\\left(x, \\vec{y}\\right) + \\frac{h}{2}\\frac{\\partial \\vec{F}}{\\partial x} + \\frac{h}{2}\\sum_{i=0}^{n-1}{\\frac{\\partial \\vec{F}}{\\partial y_i}\\cdot\\frac{\\partial y_i}{\\partial x}}\\right]\\\\\n","s\\vec{F}\\left(x + r, \\vec{y} + t\\vec{F}\\left(x, \\vec{y}\\right)\\right) &\\approx s\\vec{F}\\left(x, \\vec{y}\\right) + sr\\frac{\\partial \\vec{F}}{\\partial x}\\left(x, \\vec{y}\\right) + st\\vec{F}\\left(x, \\vec{y}\\right)\\sum_{i=0}^{n-1}{\\frac{\\partial \\vec{F}}{\\partial y_i}\\cdot\\frac{\\partial y_i}{\\partial x}}\n","\\end{align*} \n","\n","Matching terms from the last two lines above, we can see that $s = 1$, $r = \\frac{h}{2}$, and $t = \\frac{h}{2}$. Going back to the equation labeled by ($\\bigstar$) and using this substitution, we can now write\n","\n","\\begin{align*} \\vec{y}\\left(x + h\\right) &\\approx \\vec{y}\\left(x\\right) + h\\left(\\vec{F}\\left(x, \\vec{y}\\right) + \\frac{h}{2}\\vec{F}'\\left(x, \\vec{y}\\right)\\right)\\\\\n","&\\approx \\vec{y}\\left(x\\right) + h\\vec{F}\\left(x + \\frac{h}{2}, \\vec{y} + \\frac{h}{2}\\vec{F}\\left(x, \\vec{y}\\right)\\right)\n","\\end{align*}\n"],"metadata":{"id":"538axJ6v5hwJ"}},{"cell_type":"code","source":[],"metadata":{"id":"xizgXOZM3lJX"},"execution_count":null,"outputs":[]}]}