{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMUhMPYzG2Tk0HW8cJkrW0U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"28xLmiNmqLdf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Day 9: Polynomial Interpolation\n","\n","As a reminder, interpolation means fitting curves *through* existing data points. That is, our observed data points will fall exactly on the curve(s) we are constructing. It is always possible to construct a *unique* polynomial of degree at most $n-1$ that passes through $n$ distinct data points having distinct \"$x$\" coordinates."],"metadata":{"id":"G-tt5neipUEh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UsCuUjYxpOaK","cellView":"form"},"outputs":[],"source":["#@title\n","x_vals = np.random.uniform(0, 10, 4)\n","y_vals = (x_vals-4)*(x_vals-7)**2\n","\n","x_new = np.linspace(0, 10, 100)\n","y_interp = (x_new - 4)*(x_new - 7)**2\n","\n","plt.figure(figsize = (12, 4))\n","plt.scatter(x_vals, y_vals)\n","plt.plot(x_new, y_interp, color = \"red\")\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.title(\"Interpolating Data\")\n","plt.show()"]},{"cell_type":"markdown","source":["### An Example\n","\n","As usual, we'll find it helpful to have an example to work with while we introduce and discuss the methods for polynomial interpolation below.\n","\n","**Example:** Construct a degree-three polynomial interpolant for the observed data\n","\n","<center>\n","\n","x | y\n","--|--\n","1 | 4\n","5 | 12\n","7 | 8\n","15 | 20\n","\n","</center>\n","\n","> *Solution.* Keep this example in mind as we discuss the approaches below."],"metadata":{"id":"iwo5YSeGuc8P"}},{"cell_type":"code","source":["xData = np.array([1.0, 5, 7, 15])\n","yData = np.array([4.0, 12, 8, 20])\n","\n","plt.scatter(xData, yData)\n","plt.show()"],"metadata":{"id":"BJ5eeYaXjk8c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Largrange's Method\n","\n","One means of obtaining the unique polynomial described above is using Lagrange's formula:\n","\n","$$P_{n}\\left(x\\right) = \\sum_{i = 0}^{n}{y_i\\ell_{i}\\left(x\\right)}$$\n","\n","where $n$ is the degree of the polynomial and\n","\n","\\begin{align*} \\ell_{i}\\left(x\\right) &= \\left(\\frac{x - x_0}{x_i - x_0}\\right)\\left(\\frac{x - x_1}{x_i - x_1}\\right)\\cdots \\left(\\frac{x - x_{i-1}}{x_i - x_{i-1}}\\right)\\left(\\frac{x - x_{i+1}}{x_i - x_{i+1}}\\right)\\cdots \\left(\\frac{x - x_n}{x_i - x_n}\\right)\\\\\n","&= \\prod_{\\substack{j=0\\\\ j\\neq i}}^{n}{\\frac{x - x_{j}}{x_i - x_j}}~~\\text{for}~~i = 0, 1, \\cdots, n\n","\\end{align*}\n","\n","The $\\ell_{i}\\left(x\\right)$ functions are called the *cardinal functions*.\n","\n","Note that if $n = 1$ (two points), we have a linear function:\n","\n","$$P_1\\left(x\\right) = y_0\\left(\\frac{x - x_1}{x_0 - x_1}\\right) + y_1\\left(\\frac{x - x_0}{x_1 - x_0}\\right)$$\n","\n","Note also that for any $\\ell_{i}\\left(x\\right)$ and any observed data point $x_j$, we have $\\ell_{i}\\left(x_j\\right) =\\left\\{\\begin{array}{lcl} 0 &\\text{if} & j\\neq i\\\\ 1 &\\text{if} & j = i\\end{array}\\right.$. We can see this by evaluating $P_1\\left(x_0\\right)$ and $P_{1}\\left(x_1\\right)$ above.\n"],"metadata":{"id":"KtxdQE9Hqp35"}},{"cell_type":"markdown","source":["**Example:** Use the code block below to construct and plot the polynomial interpolation via Lagrange's Method for the four points at the beginning of this notebook."],"metadata":{"id":"UmOnh4CLXE8v"}},{"cell_type":"code","source":[],"metadata":{"id":"Gdfr_lfnXk6J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Approximation Error\n","\n","The function we are attempting to approximate may not actually be a polynomial. In these cases, we'll have approximation error because the functional form is incorrect. It can be shown that the error in using a polynomial interpolant $P_n\\left(x\\right)$ as an approximation for the true function $f\\left(x\\right)$ is bounded by\n","\n","$$f\\left(x\\right) - P_{n}\\left(x\\right) = \\frac{\\left(x - x_0\\right)\\left(x - x_1\\right)\\cdots \\left(x - x_n\\right)}{\\left(n+1\\right)!}f^{\\left(n+1\\right)}\\left(\\xi\\right)$$\n","\n","where $f^{\\left(n+1\\right)}$ is the $n^{th}$ derivative of the true function $f\\left(x\\right)$ and $\\xi$ is somewhere in the interval $I = \\left(x_0, x_n\\right)$.\n","\n","While Lagrange's method is relatively easy to understand, it is algorithmically inefficient. We'll explore Newton's Method as an alternative below."],"metadata":{"id":"vTMm0sPnRb8G"}},{"cell_type":"markdown","source":["## Newton's Method\n","\n","Newton's method for polynomial interpolation is to construct a polynomial of the form\n","\n","$$P_{n}\\left(x\\right) = a_0 + \\left(x - x_0\\right)a_1 + \\left(x - x_0\\right)\\left(x - x_1\\right)a_2 + \\cdots + \\left(x - x_0\\right)\\left(x - x_1\\right)\\cdots\\left(x - x_{n-1}\\right)a_n$$\n","\n","For example, a degree three polynomial (an interpolant on four data points) is given by\n","\n","\\begin{align*} P_{3}\\left(x\\right) &= a_0 + \\left(x - x_0\\right)a_1 + \\left(x - x_0\\right)\\left(x - x_1\\right)a_2 + \\left(x - x_0\\right)\\left(x - x_1\\right)\\left(x - x_2\\right)a_3\\\\\n","&= a_0 + \\left(x - x_0\\right)\\left(a_1 + \\left(x - x_1\\right)a_2 + \\left(x - x_1\\right)\\left(x - x_2\\right)a_3\\right)\\\\\n","&= a_0 + \\left(x - x_0\\right)\\left(a_1 + \\left(x - x_1\\right)\\left(a_2 + \\left(x - x_2\\right)a_3\\right)\\right)\n","\\end{align*}\n","\n","which can be evaluated backwards using the following recurrence:\n","\n","\\begin{align*} P_0\\left(x\\right) &= a_3\\\\\n","P_1\\left(x\\right) &= a_2 + \\left(x - x_2\\right)P_0\\left(x\\right)\\\\\n","P_1\\left(x\\right) &= a_1 + \\left(x - x_1\\right)P_1\\left(x\\right)\\\\\n","P_2\\left(x\\right) &= a_0 + \\left(x - x_0\\right)P_2\\left(x\\right)\n","\\end{align*}\n","\n","This doesn't just work nicely for $n = 3$ -- we have the following recurrence for any $n$.\n","\n","\\begin{align*} P_0\\left(x\\right) &= a_n\\\\\n","p_k\\left(x\\right) & = a_{n - k} + \\left(x - x_{n - k}\\right)P_{k - 1}\\left(x\\right)~~\\text{for}~~ k \\in [n]\n","\\end{align*}\n","\n","Now that we have this evaluation strategy, we can write a routine to evaluate such a polynomial!\n","\n","```\n","___ = ___\n","\n","for k in range(1, n + 1):\n","  ___ = ___[___] + (___ - ___[___])*___\n","```\n","\n","The only unfortunate thing is that we don't yet know how to determine the coefficients $a_0,~a_1,~\\cdots,~a_n$. We can determine them, however, because we know that our polynomial must pass through each of our data points. That is, for each observed data point $\\left(x_i, y_i\\right)$, we must have $y_i = P_n\\left(x_i\\right)$, which results in a simultaneous system:\n","\n","\\begin{align*} y_0 &= a_0\\\\\n","y_1 &= a_0 + \\left(x_1 - x_0\\right)a_1\\\\\n","y_2 &= a_0 + \\left(x_2 - x_0\\right)a_1 + \\left(x_2 - x_0\\right)\\left(x_2 - x_1\\right)a_2\\\\\n","&\\vdots\\\\\n","y_n &= a_0 + \\left(x_n - x_0\\right)a_1 + \\left(x_n - x_0\\right)\\left(x_n - x_1\\right)a_2 + \\cdots + \\left(x_n - x_0\\right)\\left(x_n - x_1\\right)\\cdots \\left(x_n - x_{n-1}\\right)a_{n}\n","\\end{align*}\n","\n","Note that this is not a *linear* system due to the products. However, we can solve the system if we introduce divided differences. That is,\n","\n","\\begin{align*} \\nabla y_i &= \\frac{y_i - y_0}{x_i - x_0}\\\\\n","\\nabla^2y_i &= \\frac{\\nabla y_i - \\nabla y_1}{x_i - x_1}\\\\\n","\\nabla^3y_i &= \\frac{\\nabla^2y_i - \\nabla^2y_2}{x_i - x_2}\\\\\n","&\\vdots\\\\\n","\\nabla^ny_i &= \\frac{\\nabla^{n-1}y_i - \\nabla^{n-1}y_{n-1}}{x_i - x_{n-1}}\n","\\end{align*}\n","\n","The solution of the system is then\n","\n","$$a_0 = y_0~~a_1 = \\nabla y_1~~a_2 = \\nabla^2 y_2~~\\cdots~~a_n = \\nabla^{n} y_n$$\n","\n","If we wanted to compute the coefficients by hand, we could use a tableau like the one below.\n","\n","$$\\begin{array}{|c||c|c|c|c|c|}\\hline\n","x_0 & y_0 & & & &\\\\ \\hline\n","x_1 & y_1 & \\nabla y_1 & & &\\\\ \\hline\n","x_2 & y_2 & \\nabla y_2 & \\nabla^2 y_2 & & \\\\ \\hline\n","x_3 & y_3 & \\nabla y_3 & \\nabla^2 y_3 & \\nabla^3 y_3 & \\\\ \\hline\n","x_4 & y_4 & \\nabla y_4 & \\nabla^2 y_4 & \\nabla^3 y_4 & \\nabla^4 y_4 \\\\ \\hline\n","\\end{array}$$\n","\n","The diagonals are the coefficients of our polynomial. The table entries will change depending on the order that the data points appear in our set of observations, however, the resulting polynomial does not depend on the order of the data points.\n","\n","We can compute the diagonal entries of the table numerically using a 1-D array as follows:\n","\n","```\n","a = yData.copy()\n","\n","for k in range(1, m):\n","  a[k:m] = (a[___:___] - a[___])/(xData[___:___] - xData[___])\n","```\n","\n","Initially, the array $a$ contains the column of $y$-values from the tableau. Each pass through the `for` loop creates the next column, leaving the diagonal entries of the tableau at the \"front\" of the array.\n","\n"],"metadata":{"id":"Xid-AR75v2Tf"}},{"cell_type":"markdown","source":["Finally, we are able to write the full algorithm for Newton's Method of Polynomial Interpolation."],"metadata":{"id":"bSa1c5yUMKaq"}},{"cell_type":"code","source":["## Newton's Method for Polynomial Interpolation\n","def getCoefficients(xData, yData):\n","  m = len(xData)\n","  a = yData.copy()\n","\n","  for k in range(1, m):\n","    a[k:m] = (a[___:___] - a[___])/(xData[___:___] - xData[___])\n","\n","  return a\n","\n","def evaluatePolynomial(a, xData, x):\n","  degree = ___\n","  p = ___[___]\n","\n","  for k in range(1, degree + 1):\n","    p = ___[___] + (___ - xData[___])*___\n","\n","  return ___"],"metadata":{"id":"bYeHhPdPqeat"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Example:** Verify that your function works by evaluating the following code cell. You can use more (or fewer) observed data points. You may need to adjust the $y$-limits for your plot -- you can do that by adjusting the argument to `plt.ylim()`. What happens when you use many observations? Do you trust your interpolant?"],"metadata":{"id":"aIBB5kJAJMvo"}},{"cell_type":"code","source":["xData = np.random.uniform(0, 10, 4)\n","yData = np.random.uniform(0, 10, 4)\n","\n","coefs = getCoefficients(xData, yData)\n","\n","print(coefs)\n","\n","x_new = np.linspace(0, 10, 100)\n","y_new = evaluatePolynomial(coefs, xData, x_new)\n","\n","plt.figure(figsize = (12, 4))\n","plt.scatter(xData, yData)\n","plt.plot(x_new, y_new, color = \"red\")\n","plt.ylim((-50, 50))\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.title(\"Data and Interpolated Polynomial (Newton's Method)\")\n","plt.show()"],"metadata":{"id":"aCrtt8n19b2h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Limitations to Polynomial Interpolation\n","\n","Including additional observed data points automatically increases the degree of the interpolated polynomial. This can be really detrimental, especially if there is slight noise in the measured observations. For example, consider the *nearly-linear* data points below.\n","\n","<center>\n","\n","x | y\n","--|--\n","1 | 1\n","2 | 2.1\n","3 | 2.9\n","4 | 4\n","9 | 8.9\n","\n","</center>"],"metadata":{"id":"nYJ_jGMDPjSN"}},{"cell_type":"code","source":["#@title\n","xData = np.array([1.0, 2, 3, 4, 9])\n","yData = np.array([1.0, 2.1, 2.9, 4, 8.9])\n","\n","coefs = getCoefficients(xData, yData)\n","\n","x_new = np.linspace(0, 10, 100)\n","y_new = evaluatePolynomial(coefs, xData, x_new)\n","\n","plt.figure(figsize = (12, 4))\n","plt.scatter(xData, yData, s = 100)\n","plt.plot(x_new, y_new, color = \"red\")\n","plt.plot([0, 10], [0,10], color = \"purple\")\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.title(\"Interpolated Polynomial (red) and Linear Function (purple)\")\n","plt.show()"],"metadata":{"id":"EVOykH-5I0ZN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that the interpolated polynomial has emphasized bends to accommodate the \"measurement error\". In fact, interpolated values for $x < 1$ and for $x > 4$ should probably not be trusted.\n","\n","**General Rule 1:** Polynomial *extrapolation* (interpolating outside the range of observed values) should be avoided.\n","\n","**General Rule 2:** Polynomial interpolation should be carried out with the fewest number of data points feasible. For example, if you suspect that your polynomial should be degree $2$, then use three data points. An interpolated polynomial passing through more than $6$ observed data points should be viewed with extreme suspicion -- In fact, the more data points used, the more suspicious we should be of our polynomial.\n","\n","#### A Note on Extrapolation\n","\n","Sometimes extrapolation cannot be avoided. In cases where you must extrapolate, use a low-order (small degree) polynomial interpolated only on the nearest-neighbor observations. Additionally, you should plot the interpolated polynomial for visual confirmation that the extrapolation makes sense. For example, in the plot of the interpolated polynomial on the nearly-linear data earlier, we can clearly see that using that red polynomial to extrapolate $p\\left(10\\right)$ is not a good idea."],"metadata":{"id":"uGHqX3BYRv6k"}},{"cell_type":"markdown","source":["***\n","\n","## Summary\n","\n","In this notebook we covered and implemented Newton's Method for polynomial interpolation. We completed an example of constructing an interpolated polynomial by hand (using both Lagrange's method and Newton's method) and we also used our own routine, coded in Python, to construct and evaluate an interpolated polynomial. We also highlighted some concerns to be aware of when interpolating with polynomials. In particular,\n","\n","+ We should use the fewest number of observed data points required to interpolate our polynomial (a degree $n$ polynomial requires $n+1$ data points)\n","+ We should try to avoid extrapolation (evaluating an interpolated polynomial outside of the range of observed data)\n","\n","In the next notebook we'll look at the method of interpolating with *cubic splines*.\n","\n","**Note:** There are two additional topics covered in this section of our textbook that I didn't include here.\n","\n","+ Neville's method is a faster method of polynomial interpolation appropriate for use if we only want to interpolate a single value rather than interpolating many values as we did when constructing and plotting our polynomial interpolants here.\n","+ Interpolation by rational functions is sometimes more appropriate than using polynomial interpolants. This is especially the case when there is theoretical justification for the existence of asymptotes in the relationship between the independent and dependent variables."],"metadata":{"id":"_PNG7SDQU3Is"}},{"cell_type":"code","source":[],"metadata":{"id":"En9Gd5ydQf67"},"execution_count":null,"outputs":[]}]}